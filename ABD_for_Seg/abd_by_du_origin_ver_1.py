#!/usr/bin/env python3
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import numpy as np
from scipy.ndimage import gaussian_filter1d
from scipy.spatial.distance import cosine
import cv2
import argparse
from sklearn.metrics.pairwise import cosine_similarity
import json

def export_du_segments_to_json(segments, output_path="ABD_for_CPR/du_segments.json"):
    export_list = [[start, end] for start, end in segments]
    with open(output_path, "w") as f:
        json.dump(export_list, f, indent=2)
    print(f"âœ”ï¸ Exported {len(segments)} DU segments to {output_path}")

#############################
# Feature Extraction
#############################
def extract_frame_features(video_path, grid_size=(4, 4), bins=8, frame_skip=2, resize_wh=(64, 64)):
    """
    ì˜ìƒì—ì„œ HOF(Optical Flow Histogram) featureë¥¼ ì¶”ì¶œí•œë‹¤.
    
    Args:
        video_path: ì…ë ¥ ì˜ìƒ íŒŒì¼ ê²½ë¡œ
        grid_size: ì˜ìƒ ê·¸ë¦¬ë“œ ë¶„í•  (í–‰, ì—´) â€“ ê° ê·¸ë¦¬ë“œì˜ íˆìŠ¤í† ê·¸ë¨ì„ ì¶”ì¶œ
        bins: ê° ê·¸ë¦¬ë“œì—ì„œ ì‚¬ìš©í•  íˆìŠ¤í† ê·¸ë¨ bin ê°œìˆ˜ (ê°ë„ 0~360)
        frame_skip: ëª‡ í”„ë ˆì„ë§ˆë‹¤ ì²˜ë¦¬í• ì§€ (ì†ë„ ì¡°ì ˆìš©)
        resize_wh: ì˜ìƒì˜ ë¦¬ì‚¬ì´ì¦ˆ í¬ê¸° (ë„ˆë¹„, ë†’ì´)
    
    Returns:
        hof_features: (N x D) numpy array, Nì€ ì¶”ì¶œëœ frame ìˆ˜, DëŠ” feature ì°¨ì›
        frame_skip: ì‹¤ì œë¡œ ì‚¬ìš©ëœ frame_skip ê°’
    """
    cap = cv2.VideoCapture(video_path)
    prev_gray = None
    hof_features = []
    frame_idx = 0

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        if frame_idx % frame_skip != 0:
            frame_idx += 1
            continue

        resized = cv2.resize(frame, resize_wh)
        gray = cv2.cvtColor(resized, cv2.COLOR_BGR2GRAY)

        if prev_gray is not None:
            flow = cv2.calcOpticalFlowFarneback(prev_gray, gray,
                                                None, 0.5, 3, 15, 3, 5, 1.2, 0)
            mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1], angleInDegrees=True)
            h, w = gray.shape
            cell_h, cell_w = h // grid_size[0], w // grid_size[1]
            hof_vec = []

            for i in range(grid_size[0]):
                for j in range(grid_size[1]):
                    y1, y2 = i * cell_h, (i + 1) * cell_h
                    x1, x2 = j * cell_w, (j + 1) * cell_w
                    angle = ang[y1:y2, x1:x2].flatten()
                    magnitude = mag[y1:y2, x1:x2].flatten()
                    hist, _ = np.histogram(angle, bins=bins, range=(0, 360), weights=magnitude)
                    hof_vec.extend(hist)

            hof_features.append(hof_vec)

        prev_gray = gray
        frame_idx += 1

    cap.release()
    return np.array(hof_features), frame_skip

#############################
# Smoothing and Similarity
#############################
def smooth_features(features, sigma=2):
    """
    Gaussian í•„í„°ë¥¼ ì´ìš©í•˜ì—¬ í”„ë ˆì„ë³„ featureì— ëŒ€í•´ smoothing ìˆ˜í–‰.
    
    Args:
        features: (N x D) numpy array, frameë³„ feature
        sigma: Gaussian smoothingì— ì‚¬ìš©ë  sigma ê°’
    
    Returns:
        smoothed_features: (N x D) numpy array
    """
    return gaussian_filter1d(features, sigma=sigma, axis=0)

def cosine_sim(a, b):
    """
    ë‘ ë²¡í„° ê°„ cosine similarityë¥¼ ê³„ì‚° (scipy.spatial.distance.cosineì€ cosine distance ë¦¬í„´í•˜ë¯€ë¡œ ë³€í™˜)
    """
    return 1 - cosine(a, b)

def compute_similarities(smoothed):
    """
    ì—°ì†ëœ í”„ë ˆì„ ê°„ cosine similarityë¥¼ ê³„ì‚°.
    
    Args:
        smoothed: (N x D) numpy array, smoothingëœ feature
    
    Returns:
        similarities: ë¦¬ìŠ¤íŠ¸ (ê¸¸ì´: N-1) cosine similarity ê°’
    """
    return [cosine_sim(smoothed[i], smoothed[i+1]) for i in range(len(smoothed)-1)]

#############################
# Boundary Detection & Segmentation
#############################
def detect_boundaries(similarities, window_size=10, min_boundaries=30):
    """
    cosine similarity ì‹œí€€ìŠ¤ì— ëŒ€í•´ NMS ê¸°ë°˜ ê²½ê³„ ê²€ì¶œ.
    ë˜í•œ, ê²½ê³„ ê°œìˆ˜ê°€ min_boundaries ë¯¸ë§Œì´ë©´ ì¼ì • ê°„ê²©ìœ¼ë¡œ ì¶”ê°€.
    
    Args:
        similarities: 1ì°¨ì› ë¦¬ìŠ¤íŠ¸ í˜¹ì€ array, ì—°ì† í”„ë ˆì„ ê°„ cosine similarity
        window_size: ë¡œì»¬ ìœˆë„ìš° í¬ê¸°
        min_boundaries: ìµœì†Œ ìš”êµ¬ ê²½ê³„ ìˆ˜ (ë„ˆë¬´ ì ì€ ê²½ìš° ë³´ì™„)
    
    Returns:
        boundaries: ê²½ê³„ ì¸ë±ìŠ¤ ë¦¬ìŠ¤íŠ¸ (í”„ë ˆì„ index ê¸°ì¤€)
    """
    boundaries = []
    for i in range(window_size, len(similarities) - window_size):
        local = similarities[i - window_size : i + window_size + 1]
        if similarities[i] == min(local):
            boundaries.append(i)
            
    if len(boundaries) < min_boundaries:
        total = len(similarities)
        step = total // (min_boundaries + 1)
        extra = list(range(step, total, step))
        boundaries = list(set(boundaries + extra))
    
    return sorted(boundaries)

def segment_from_boundaries(boundaries, total_length):
    """
    ê²½ê³„ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ segmentë¥¼ ìƒì„±.
    
    Args:
        boundaries: ê²½ê³„ ì¸ë±ìŠ¤ ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: [b1, b2, ..., bn])
        total_length: ì „ì²´ frame ìˆ˜
    
    Returns:
        segments: ê° segmentë¥¼ (start, end) íŠœí”Œë¡œ ë‚˜íƒ€ë‚¸ ë¦¬ìŠ¤íŠ¸.
                  ì‹œì‘ê³¼ ë ê²½ê³„ëŠ” ìë™ìœ¼ë¡œ í¬í•¨ì‹œí‚´.
    """
    boundaries = [0] + boundaries + [total_length]
    segments = []
    for i in range(len(boundaries)-1):
        segments.append( (boundaries[i], boundaries[i+1]) )
    return segments

def visualize_segments_with_boundaries(similarities, segments, boundaries):
    plt.figure(figsize=(14, 5))
    plt.plot(similarities, label="Cosine Similarity", color="blue")
    
    ## boundary ì  í‘œì‹œ
    #for b in boundaries:
    #    plt.axvline(x=b, color='red', linestyle='--', alpha=0.7)

    cmap = cm.get_cmap("Set3", len(segments))
    for i, (start, end) in enumerate(segments):
        plt.axvspan(start, end, alpha=0.3, color=cmap(i), label=f"Seg {i+1}")
        
    #plt.title("Action Boundary Detection Visualization (with candidate boundaries)")
    plt.title("Action Boundary Detection Visualization")
    plt.xlabel("Frame Index")
    plt.ylabel("Cosine Similarity")
    plt.legend(loc="lower right")
    #plt.tight_layout()
    plt.show()




def cosine_sim(a, b):
    return 1 - cosine(a, b)

def estimate_k_by_duration(total_frames, fps=60, target_duration_sec=8):
    """
    ì „ì²´ í”„ë ˆì„ ìˆ˜ì™€ íƒ€ê²Ÿ ì„¸ê·¸ë¨¼íŠ¸ ì‹œê°„(ì´ˆ)ì„ ê¸°ì¤€ìœ¼ë¡œ ìë™ K ì¶”ì •
    """
    video_duration = total_frames / fps
    est_k = int(round(video_duration / target_duration_sec))
    return max(est_k, 1)

def refine_segments_with_temporal_bias(features, segment_boundaries, target_K=None, lambda_penalty=0.005, fps=60, target_duration_sec=8):
    """
    ì‹œê°„ì  ê±°ë¦¬ ê³ ë ¤í•˜ì—¬ ì„¸ê·¸ë¨¸íŠ¸ ë°€í¬
    Args:
        features: (N x D) numpy array, frame-wise features
        segment_boundaries: list of (start, end) tuples
        target_K: ìµœì¢… ì›í•˜ëŠ” ì„¸ê·¸ë¨¸íŠ¸ ìˆ˜. Noneì´ë©´ ìë™ ê³„ì‚°
        lambda_penalty: ì‹œê°„ ê±°ë¦¬ íŒ¨ë„í‹° ê°€ìš©ì¹˜
        fps: frame per second
        target_duration_sec: ì›í•˜ëŠ” ê° ì„¸ê·¸ë¨¸íŠ¸ ê¸°ê°„
    Returns:
        segment_boundaries: (start, end) íˆ´í¼ ë¦¬ìŠ¤íŠ¸
    """
    if target_K is None:
        total_frames = segment_boundaries[-1][1]  # ë§ˆì§€ë§‰ end frame
        target_K = estimate_k_by_duration(total_frames, fps=fps, target_duration_sec=target_duration_sec)

    # Step 1: segment-wise í‰ê·  feature ê³„ì‚°
    segment_features = []
    for start, end in segment_boundaries:
        segment_feat = np.mean(features[start:end], axis=0)
        segment_features.append(segment_feat)

    while len(segment_features) > target_K:
        M = len(segment_features)
        best_score = -np.inf
        best_pair = (0, 1)

        for i in range(M):
            for j in range(i + 1, M):
                # cosine similarity
                cos_sim = cosine_sim(segment_features[i], segment_features[j])
                # ì‹œê°„ ì¤‘ì‹¬ ê±°ë¦¬
                ci = (segment_boundaries[i][0] + segment_boundaries[i][1]) / 2
                cj = (segment_boundaries[j][0] + segment_boundaries[j][1]) / 2
                temporal_dist = abs(ci - cj)
                score = cos_sim - lambda_penalty * temporal_dist

                if score > best_score:
                    best_score = score
                    best_pair = (i, j)

        # ë³‘í•© ìˆ˜í–‰
        i, j = best_pair
        start_i, end_i = segment_boundaries[i]
        start_j, end_j = segment_boundaries[j]
        new_start = min(start_i, start_j)
        new_end = max(end_i, end_j)
        new_feat = (segment_features[i] * (end_i - start_i) + segment_features[j] * (end_j - start_j)) / (new_end - new_start)

        # ë¦¬ìŠ¤íŠ¸ ê°±ì‹ 
        new_segment_boundaries = []
        new_segment_features = []
        for idx in range(len(segment_features)):
            if idx in [i, j]:
                continue
            new_segment_boundaries.append(segment_boundaries[idx])
            new_segment_features.append(segment_features[idx])
        new_segment_boundaries.append((new_start, new_end))
        new_segment_features.append(new_feat)

        segment_boundaries = new_segment_boundaries
        segment_features = new_segment_features

    return segment_boundaries

#############################
# Main Pipeline
#############################
def run_abd_safe(video_path, sigma=2, window_size=10, min_boundaries=30, frame_skip=2, K=0, fps=60):
    """
    ì˜ìƒ íŒŒì¼ì„ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ ABD íŒŒì´í”„ë¼ì¸ì„ ìˆ˜í–‰í•œë‹¤.
    1. HOF ê¸°ë°˜ feature ì¶”ì¶œ
    2. Gaussian smoothing
    3. í”„ë ˆì„ ê°„ cosine similarity ê³„ì‚°
    4. NMS ê¸°ë°˜ ê²½ê³„ ê²€ì¶œ (ìœ ì‚¬ë„ê°€ ë‚®ì€ ì§€ì )
    5. ê²½ê³„ë¡œë¶€í„° ì´ˆê¸° segmentation ìƒì„±
    6. (ì˜µì…˜) ëª©í‘œ segment ìˆ˜ Kê°€ ì£¼ì–´ì§€ë©´ refinement ìˆ˜í–‰ (ì¸ì ‘í•œ segment ë³‘í•©)
    7. ê²°ê³¼ ì‹œê°í™” ë° segment ì •ë³´ ì¶œë ¥
    
    Args:
        video_path: ì…ë ¥ ì˜ìƒ ê²½ë¡œ
        sigma: Gaussian smoothingì˜ sigma ê°’
        window_size: boundary ê²€ì¶œ ì‹œ ì‚¬ìš©í•  ìœˆë„ìš° í¬ê¸°
        min_boundaries: ìµœì†Œ ê²½ê³„ ê°œìˆ˜ (ë¶€ì¡±í•  ê²½ìš° ë³´ì™„)
        frame_skip: feature ì¶”ì¶œ ì‹œ ê±´ë„ˆë›¸ frame ê°„ê²©
        K: ìµœì¢… ëª©í‘œ segment ìˆ˜ (0ì´ë©´ refinement ìˆ˜í–‰í•˜ì§€ ì•ŠìŒ)
        fps: ì˜ìƒì˜ ì´ˆë‹¹ í”„ë ˆì„ ìˆ˜ (segment duration ê³„ì‚°ìš©)
    
    Returns:
        segments: (start, end) íŠœí”Œ ë¦¬ìŠ¤íŠ¸, ê° segmentì˜ ì‹œì‘/ë frame index
    """
    # 1. Feature ì¶”ì¶œ
    print(f"video_path: {video_path}")
    features, frame_skip_used = extract_frame_features(video_path, frame_skip=frame_skip)
    print(f"[âœ”] {len(features)} framesì˜ feature ì¶”ì¶œ ì™„ë£Œ (frame_skip={frame_skip_used})")
    
    # 2. Gaussian smoothing
    smoothed_features = smooth_features(features, sigma=sigma)
    
    # 3. ì—°ì† í”„ë ˆì„ ê°„ cosine similarity ê³„ì‚°
    similarities = compute_similarities(smoothed_features)
    
    # 4. ê²½ê³„ ê²€ì¶œ (similarities ê¸°ë°˜)
    boundaries = detect_boundaries(similarities, window_size=window_size, min_boundaries=min_boundaries)
    print(f"[âœ”] ê²€ì¶œëœ ê²½ê³„ í›„ë³´ (similarity index ê¸°ì¤€): {boundaries}")
    
    # 5. ì´ˆê¸° segmentation (boundary ë¦¬ìŠ¤íŠ¸ë¥¼ ì´ìš©í•˜ì—¬)
    segments_init = segment_from_boundaries(boundaries, total_length=len(features))
    
    # 6. (ì˜µì…˜) over-segmentation refinement: ì¸ì ‘ segment ë³‘í•© ë°©ì‹ ì ìš©
    if K > 0 and len(segments_init) > K:
        # refine_segments_adjacentë¥¼ ìœ„í•´ boundaries ë¦¬ìŠ¤íŠ¸ ì¬êµ¬ì„±
        refined_boundaries = refine_segments_with_temporal_bias(smoothed_features, segments_init, K, lambda_penalty=0.005)
        segments_final = refined_boundaries
        print(f"[âœ”] Refinement ìˆ˜í–‰ í›„ ìµœì¢… segment ìˆ˜: {len(segments_final)}")
    else:
        segments_final = segments_init
        print(f"[âœ”] Refinement ë¯¸ìˆ˜í–‰ (ì´ˆê¸° segment ìˆ˜: {len(segments_final)})")
    
    # 7. Segment ì •ë³´ ì¶œë ¥ (ì‹¤ì œ frame indexë¡œ í™˜ì‚°: frame_skip ë°˜ì˜)

    segments_final = sorted(segments_final, key=lambda x: x[0])  # ğŸ”¥ ì •ë ¬ ì¶”ê°€
    print("\n[Segment Info]")
    for i, (start, end) in enumerate(segments_final):
        real_start = start * frame_skip_used
        real_end = end * frame_skip_used
        duration = (real_end - real_start) / fps
        print(f"Segment {i+1}: Frame {real_start} â†’ {real_end} ({duration:.2f} sec)")
        print(f"         ì‹œì‘: {real_start/fps:.2f}ì´ˆ, ë: {real_end/fps:.2f}ì´ˆ")
        
    # 8. ì‹œê°í™”
    visualize_segments_with_boundaries(similarities, refined_boundaries, boundaries)
    export_du_segments_to_json(segments_final)
    
    return segments_final

#############################
# Argument Parsing & Main()
#############################
def main():
    parser = argparse.ArgumentParser(
        description="Fast and Unsupervised Action Boundary Detection (ABD)"
    )
    parser.add_argument('--video_path', type=str, default="../CPR_data/CPR_frontview.mp4",
                        help="ì…ë ¥ ì˜ìƒ íŒŒì¼ ê²½ë¡œ")
    parser.add_argument('--sigma', type=float, default=2.0,
                        help="Gaussian smoothingì— ì‚¬ìš©í•  sigma ê°’")
    parser.add_argument('--window_size', type=int, default=10,
                        help="boundary ê²€ì¶œì„ ìœ„í•œ ìœˆë„ìš° í¬ê¸°")
    parser.add_argument('--min_boundaries', type=int, default=30,
                        help="ìµœì†Œ ê²½ê³„ ê°œìˆ˜ (ë¶€ì¡±í•  ê²½ìš° ë³´ì™„)")
    parser.add_argument('--frame_skip', type=int, default=2,
                        help="feature ì¶”ì¶œ ì‹œ ê±´ë„ˆë›¸ frame ê°„ê²©")
    parser.add_argument('--K', type=int, default=19,
                        help="ìµœì¢… ëª©í‘œ segment ìˆ˜ (0ì´ë©´ refinement ìˆ˜í–‰í•˜ì§€ ì•ŠìŒ)")
    parser.add_argument('--fps', type=float, default=60,
                        help="ì˜ìƒì˜ ì´ˆë‹¹ í”„ë ˆì„ ìˆ˜ (duration ê³„ì‚°ìš©)")
    args = parser.parse_args()
    
    run_abd_safe(video_path=args.video_path, sigma=args.sigma, window_size=args.window_size,
                 min_boundaries=args.min_boundaries, frame_skip=args.frame_skip, K=args.K, fps=args.fps)

if __name__ == "__main__":
    main()
